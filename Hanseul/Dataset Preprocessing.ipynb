{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dcf4621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h5py 안 될 때 (M1 Mac)\n",
    "#!brew reinstall hdf5\n",
    "#!export CPATH=\"/opt/homebrew/include/\"\n",
    "#!export HDF5_DIR=/opt/homebrew/\n",
    "#!python3 -m pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bba8e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ddf6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = '../'\n",
    "path_container = './Container/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2b6971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = os.path.join(path_root, \"train.csv\")\n",
    "path_valid_class_que = os.path.join(path_root, \"validation_classification_question.csv\")\n",
    "path_valid_class_ans = os.path.join(path_root, \"validation_classification_answer.csv\")\n",
    "path_valid_compl_que = os.path.join(path_root, \"validation_completion_question.csv\")\n",
    "path_valid_compl_ans = os.path.join(path_root, \"validation_completion_answer.csv\")\n",
    "path_test_class_que = os.path.join(path_root, \"test_classification_question.csv\")\n",
    "path_test_compl_que = os.path.join(path_root, \"test_completion_question.csv\")\n",
    "path_ingredient_name = os.path.join(path_root, \"node_ingredient.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adcf00c",
   "metadata": {},
   "source": [
    "### Data 읽어서 list로 일단 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34dd278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_data(path):\n",
    "    \"\"\" Read train.csv and Return lists of data[int] / label[str]. \"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in csv.reader(f):\n",
    "            recipe = sorted(map(int, line[:-1]))  # a sorted list of recipe (integer)\n",
    "            cuisine = line[-1]                    # which country? (string)\n",
    "            data.append(recipe)\n",
    "            labels.append(cuisine)\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def read_classification_data(question_path, answer_path=None):\n",
    "    \"\"\" Read valid/test data for classification. Then return lists of data[int] / label[str]. \"\"\"\n",
    "    data = []\n",
    "    labels = [] if answer_path is not None else None\n",
    "    with open(question_path, 'r') as f:\n",
    "        for line in csv.reader(f):\n",
    "            recipe = sorted(map(int, line))  # a sorted list of recipe (integer)\n",
    "            data.append(recipe)\n",
    "    if answer_path is not None:\n",
    "        with open(answer_path, 'r') as f:\n",
    "            for line in csv.reader(f):\n",
    "                cuisine = line[0]            # which country? (string)\n",
    "                labels.append(cuisine)\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def read_completion_data(question_path, answer_path=None):\n",
    "    \"\"\" Read valid/test data for completion. Then return lists of data[int] / label[str]. \"\"\"\n",
    "    data = []\n",
    "    labels = [] if answer_path is not None else None\n",
    "    with open(question_path, 'r') as f:\n",
    "        for line in csv.reader(f):\n",
    "            recipe = sorted(map(int, line))                # recipe without an ingredient\n",
    "            data.append(recipe)\n",
    "    if answer_path is not None:\n",
    "        with open(answer_path, 'r') as f:\n",
    "            for line in csv.reader(f):\n",
    "                recipe = set(map(int, line))               # original recipe\n",
    "                missing = recipe - set(data[len(labels)])  # missing ingredient in data\n",
    "                labels.append(list(missing)[0])\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def read_ingredient_names(ingredient_path):\n",
    "    ingredients_names = []\n",
    "    with open(ingredient_path, 'r') as f:\n",
    "        for line in csv.reader(f):\n",
    "            ingredients_names.append(line[0])\n",
    "    return ingredients_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b11ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, labels_train = read_train_data(path_train)\n",
    "data_valid_class, labels_valid_class = read_classification_data(path_valid_class_que, path_valid_class_ans)\n",
    "data_valid_compl, labels_valid_compl = read_completion_data(path_valid_compl_que, path_valid_compl_ans)\n",
    "data_test_class, _ = read_classification_data(path_test_class_que, None)\n",
    "data_test_compl, _ = read_completion_data(path_test_compl_que, None)\n",
    "ingredient_names = read_ingredient_names(path_ingredient_name)  # 재료 이름 (string)\n",
    "cuisine_names = sorted(set(labels_train+labels_valid_class))    # Cuisine 이름 (string), 알파벳 순"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45b43b1",
   "metadata": {},
   "source": [
    "### List (```ingredient_names```, ```cuisine_names```) 를 Dictionary로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf8098d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'brazilian', 1: 'british', 2: 'cajun_creole', 3: 'chinese', 4: 'filipino', 5: 'french', 6: 'greek', 7: 'indian', 8: 'irish', 9: 'italian', 10: 'jamaican', 11: 'japanese', 12: 'korean', 13: 'mexican', 14: 'moroccan', 15: 'russian', 16: 'southern_us', 17: 'spanish', 18: 'thai', 19: 'vietnamese'}\n"
     ]
    }
   ],
   "source": [
    "# Dict: id (int, 0~19) -> cuisine name (str, 알파벳 순)\n",
    "id_cuisine_dict = dict(zip(range(len(cuisine_names)), cuisine_names))\n",
    "print(id_cuisine_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af227545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'brazilian': 0, 'british': 1, 'cajun_creole': 2, 'chinese': 3, 'filipino': 4, 'french': 5, 'greek': 6, 'indian': 7, 'irish': 8, 'italian': 9, 'jamaican': 10, 'japanese': 11, 'korean': 12, 'mexican': 13, 'moroccan': 14, 'russian': 15, 'southern_us': 16, 'spanish': 17, 'thai': 18, 'vietnamese': 19}\n"
     ]
    }
   ],
   "source": [
    "# Dict: cuisine name (str) -> id (int)\n",
    "cuisine_id_dict = {b: a for a, b in id_cuisine_dict.items()}\n",
    "print(cuisine_id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d80dced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6714\n",
      "{0: 'coca-cola', 1: 'vegan butter', 2: 'sourdough rolls', 3: 'reduced sodium refried beans', 4: 'ramen noodles', 5: 'crumbled corn bread', 6: 'japanese breadcrumbs', 7: 'toasted shredded coconut', 8: 'chinese spinach', 9: \"Hellmann's® Real Mayonnaise\", 10: 'ducklings', 11: 'basil olive oil', 12: 'white baking bar', 13: 'rye whiskey', 14: 'mushroom broth', 15: 'meat loaf mix', 16: 'cocktail sauce', 17: 'asparagus spears', 18: 'nonfat greek yogurt', 19: 'cabernet sauvignon'} ...\n"
     ]
    }
   ],
   "source": [
    "# Dict: id (int, 0~6713) -> ingredient name (str, node_ingredient.txt 기준)\n",
    "id_ingredient_dict = dict(zip(range(len(ingredient_names)), ingredient_names))\n",
    "print(len(id_ingredient_dict.items()))\n",
    "print(dict(list(id_ingredient_dict.items())[:20]), '...')  # 20개만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab8f3c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@ Duplicate ingredients: (19개) @@@\n",
      "      [917, 3335] (10 oz.) frozen chopped spinach\n",
      "      [585, 4634] bacon\n",
      "[698, 1039, 4315] bread\n",
      "     [3297, 5457] clams\n",
      "     [5368, 5932] cream cheese\n",
      "      [984, 4593] egg noodles\n",
      "     [3403, 4936] frozen chopped spinach\n",
      "     [3700, 5810] frozen lemonade concentrate\n",
      "       [83, 3076] frozen orange juice concentrate\n",
      "     [4999, 5908] green bell pepper\n",
      "     [4047, 4091] lasagna noodles\n",
      "     [2353, 4243] linguine\n",
      "     [2882, 3311] mussels\n",
      "      [343, 2798] pork chops\n",
      "     [4945, 5095] red bell pepper\n",
      "     [2938, 3099] spaghetti\n",
      "     [1063, 4921] tortellini\n",
      "     [5656, 6442] tuna\n",
      "     [1660, 6510] water chestnuts\n",
      "\n",
      "number of non-duplicate ingredient names: 6694\n",
      "{'coca-cola': 0, 'vegan butter': 1, 'sourdough rolls': 2, 'reduced sodium refried beans': 3, 'ramen noodles': 4, 'crumbled corn bread': 5, 'japanese breadcrumbs': 6, 'toasted shredded coconut': 7, 'chinese spinach': 8, \"Hellmann's® Real Mayonnaise\": 9, 'ducklings': 10, 'basil olive oil': 11, 'white baking bar': 12, 'rye whiskey': 13, 'mushroom broth': 14, 'meat loaf mix': 15, 'cocktail sauce': 16, 'asparagus spears': 17, 'nonfat greek yogurt': 18, 'cabernet sauvignon': 19} ...\n"
     ]
    }
   ],
   "source": [
    "# Dict: ingredient name (str) -> id (int, 0~6713)\n",
    "ingredient_id_dict = dict()\n",
    "duplicate_ingredient_names = set()\n",
    "for i, (a, b) in enumerate(id_ingredient_dict.items()):\n",
    "    if b in ingredient_id_dict:\n",
    "        duplicate_ingredient_names.add(b)\n",
    "        if type(ingredient_id_dict[b]) == int:\n",
    "            ingredient_id_dict[b] = [ingredient_id_dict[b], a]\n",
    "            #ingredient_id_dict[b] = [ingredient_id_dict[b], a]\n",
    "        else:\n",
    "            ingredient_id_dict[b] += [a]\n",
    "            #ingredient_id_dict[b] = tuple(list(ingredient_id_dict[b]) + [a])\n",
    "    else:\n",
    "        ingredient_id_dict[b] = a\n",
    "print(f'@@@ Duplicate ingredients: ({len(duplicate_ingredient_names)}개) @@@')\n",
    "for name in sorted(duplicate_ingredient_names):\n",
    "    print(f\"{str(ingredient_id_dict[name]):>17} {name}\")\n",
    "print()\n",
    "print('number of non-duplicate ingredient names:', len(ingredient_id_dict))\n",
    "print(dict(list(ingredient_id_dict.items())[:20]), '...')  # 20개만 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c04da8",
   "metadata": {},
   "source": [
    "### Data, Label lists를 binary np.array로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2445c1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_binary_array(data, dim):\n",
    "    \"\"\" convert data(list of lists) into a 2D binary array. (for dataset, row = recipe) \"\"\"\n",
    "    \"\"\" dim (int) : dimension of each row (of 'enc') that must be. \"\"\"\n",
    "    enc = np.zeros((len(data), dim), dtype=int) \n",
    "    for i in range(len(data)):\n",
    "        recipe = data[i]\n",
    "        enc[i][recipe] = 1\n",
    "    return enc\n",
    "\n",
    "num_ingredients = len(ingredient_names)\n",
    "num_cuisines = len(cuisine_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6994d4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23547, 6714)\n",
      "(7848, 6714)\n",
      "(7848, 6714)\n",
      "(3924, 6714)\n",
      "(3924, 6714)\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "bin_data_train = data_to_binary_array(data_train, num_ingredients)\n",
    "bin_data_valid_class = data_to_binary_array(data_valid_class, num_ingredients)\n",
    "bin_data_valid_compl = data_to_binary_array(data_valid_compl, num_ingredients)\n",
    "bin_data_test_class = data_to_binary_array(data_test_class, num_ingredients)\n",
    "bin_data_test_compl = data_to_binary_array(data_test_compl, num_ingredients)\n",
    "\n",
    "for x in [bin_data_train, bin_data_valid_class, bin_data_valid_compl, bin_data_test_class, bin_data_test_compl]:\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f60242fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23547,)\n",
      "(7848,)\n",
      "(7848,)\n"
     ]
    }
   ],
   "source": [
    "# String이던 Label을 id로 바꾸기\n",
    "int_labels_train = np.array([cuisine_id_dict[label] for label in labels_train])\n",
    "int_labels_valid_class = np.array([cuisine_id_dict[label] for label in labels_valid_class])\n",
    "int_labels_valid_compl = np.array(labels_valid_compl)  # 원래 int형.\n",
    "\n",
    "for x in [int_labels_train, int_labels_valid_class, int_labels_valid_compl]:\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a6eab2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23547, 20)\n",
      "(7848, 20)\n",
      "(7848, 6714)\n"
     ]
    }
   ],
   "source": [
    "# int형 label을 one-hot으로 바꾸기\n",
    "bin_labels_train = data_to_binary_array(int_labels_train, num_cuisines)\n",
    "bin_labels_valid_class = data_to_binary_array(int_labels_valid_class, num_cuisines)\n",
    "bin_labels_valid_compl = data_to_binary_array(labels_valid_compl, num_ingredients)\n",
    "\n",
    "for x in [bin_labels_train, bin_labels_valid_class, bin_labels_valid_compl]:\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f111083",
   "metadata": {},
   "source": [
    "### Dictionary를 pickle로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf124dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %mkdir {path_container}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b965c23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "6714\n",
      "6694\n"
     ]
    }
   ],
   "source": [
    "for d, name in zip([id_cuisine_dict, cuisine_id_dict, id_ingredient_dict, ingredient_id_dict],\n",
    "                   ['id_cuisine_dict', 'cuisine_id_dict', 'id_ingredient_dict', 'ingredient_id_dict']):\n",
    "    print(len(d))\n",
    "    with open(path_container + name +'.pickle', 'wb') as fw:\n",
    "        pickle.dump(d, fw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1adea6",
   "metadata": {},
   "source": [
    "### np.ndarray를 h5py로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08598836",
   "metadata": {},
   "outputs": [],
   "source": [
    "_train = [bin_data_train, int_labels_train, bin_labels_train]\n",
    "_valid_class = [bin_data_valid_class, int_labels_valid_class, bin_labels_valid_class]\n",
    "_valid_compl = [bin_data_valid_compl, int_labels_valid_compl, bin_labels_valid_compl]\n",
    "_test_class = [bin_data_test_class, None, None]\n",
    "_test_compl = [bin_data_test_compl, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93ccda54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (bin_data, int_labels, bin_labels), name in zip([_train, _valid_class, _valid_compl, _test_class, _test_compl],\n",
    "                                                    ['train', 'valid_class', 'valid_compl', 'test_class', 'test_compl']):\n",
    "    with h5py.File(path_container + name, 'w') as h5f:\n",
    "        h5f.create_dataset('bin_data', data=bin_data, compression=\"gzip\")\n",
    "        if 'test_' not in name:\n",
    "            h5f.create_dataset('int_labels', data=int_labels, compression=\"gzip\")\n",
    "            h5f.create_dataset('bin_labels', data=bin_labels, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67802707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c611dcb9",
   "metadata": {},
   "source": [
    "## 각 재료는 얼마나 등장할까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2539200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_cnt 253459\n",
      "non-appear ingred? 855\n",
      "   plain    | label_appearance\n",
      " 937: 10683 |  937: 1029.238668427132\n",
      "5377:  4764 | 5377: 451.9161677791333\n",
      "5536:  4685 | 2945: 428.95297773804896\n",
      "2945:  4347 | 1308: 406.3646566533548\n",
      "6187:  4329 | 5536: 395.38299815444026\n",
      "1308:  3759 | 6187: 371.3897284542667\n",
      "2122:  3713 | 2122: 325.11233138262673\n",
      "2518:  2859 | 5648: 296.83767796850793\n",
      "5648:  2809 | 4799: 273.021986953124\n",
      "4799:  2739 | 2518: 252.05825911713433\n",
      "2813:  2631 |  167: 241.8706030228799\n",
      " 167:  2594 | 2813: 239.94656738638224\n",
      "1476:  2007 | 1476: 204.08035320744452\n",
      "3978:  1928 | 2809: 176.3161334401818\n",
      "3653:  1861 | 5882: 174.30191173884472\n",
      "  59:  1834 | 3978: 173.16011293968384\n",
      "5884:  1808 | 3653: 172.29724214725792\n",
      "2809:  1755 | 1679: 167.37086058738828\n",
      "5882:  1658 | 5884: 161.3637390092757\n",
      "5136:  1637 |   59: 161.3332578924371\n"
     ]
    }
   ],
   "source": [
    "# 매 epoch 마다 한 recipe는 한 번씩 뽑힌다. 그리고 completion에서는 그 중 하나의 재료씩 뽑힌다.\n",
    "plain_appearance = np.zeros(6714, dtype=int)  # dataset에 등장한 횟수 세기\n",
    "label_appearance = np.zeros(6714)             # completion label로 뽑힐 횟수 (in average, relative) 세기\n",
    "total_cnt = 0\n",
    "for recipe in data_train:\n",
    "    for ingredient in recipe:\n",
    "        plain_appearance[ingredient] += 1\n",
    "        if len(recipe) >= 2:\n",
    "            label_appearance[ingredient] += 1/len(recipe)\n",
    "        total_cnt += 1\n",
    "\n",
    "print('total_cnt', total_cnt)\n",
    "print('non-appear ingred?', (plain_appearance==0).sum())\n",
    "\n",
    "# 상위 20개만 보여주기\n",
    "print('   plain    | label_appearance')\n",
    "_i = 1\n",
    "for (i, num1), (j, num2) in zip(sorted(list(enumerate(plain_appearance)), key=lambda x: -x[1]),\n",
    "                   sorted(list(enumerate(label_appearance)), key=lambda x: -x[1])):\n",
    "    print(f\"{i:4d}: {num1:5d} | {j:4d}: {num2}\")\n",
    "    _i += 1\n",
    "    if _i > 20:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2210c2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/6714 = 0.00014894250819183795\n",
      "\n",
      "2826: 0.00183632\n",
      "5514: 0.00183632\n",
      " 967: 0.00173038\n",
      "1227: 0.00173038\n",
      "4280: 0.00123598\n",
      "5522: 0.00123598\n",
      "1512: 0.00113004\n",
      "4041: 0.00113004\n",
      "4189: 0.00102410\n",
      "4910: 0.00102410\n",
      " 653: 0.00098879\n",
      "3522: 0.00098879\n",
      "5096: 0.00095347\n",
      "5826: 0.00095347\n",
      "5401: 0.00091816\n",
      "  11: 0.00088284\n",
      "1195: 0.00088284\n",
      "1581: 0.00088284\n",
      "1800: 0.00088284\n",
      "2494: 0.00088284\n"
     ]
    }
   ],
   "source": [
    "label_weight = np.zeros(6714)\n",
    "\n",
    "#inverse appearance, ignoring not appeared ingreds\n",
    "label_weight[label_appearance > 0] = 1 / label_appearance[label_appearance > 0]\n",
    "label_weight /= label_weight.sum()  # normalize: sum to be 1\n",
    "\n",
    "assert label_weight.sum() == 1\n",
    "\n",
    "print(\"1/6714 =\", 1/6714)\n",
    "print()\n",
    "# 상위 20개만 보여주기\n",
    "_i = 1\n",
    "for i, num in sorted(list(enumerate(label_weight)), key=lambda x: -x[1]):\n",
    "    print(f\"{i:4d}: {num:.8f}\")\n",
    "    _i += 1\n",
    "    if _i>20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d41f8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_container + 'label_weight_compl.pickle', 'wb') as fw:\n",
    "        pickle.dump(label_weight, fw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f26e918",
   "metadata": {},
   "source": [
    "## 각 Cuisine은 얼마나 등장할까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "83e9bc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9: 4678\n",
      "13: 3836\n",
      "16: 2515\n",
      " 7: 1748\n",
      " 3: 1599\n",
      " 5: 1543\n",
      " 2: 920\n",
      "18: 903\n",
      "11: 840\n",
      " 6: 714\n",
      "17: 590\n",
      "14: 496\n",
      "19: 487\n",
      " 1: 485\n",
      "12: 474\n",
      " 4: 452\n",
      " 8: 404\n",
      "15: 300\n",
      " 0: 283\n",
      "10: 280\n"
     ]
    }
   ],
   "source": [
    "label_count_class = [np.count_nonzero(int_labels_train==i) for i in range(20)]\n",
    "for i, _cnt in sorted(list(enumerate(label_count_class)), key=lambda x: -x[1]):\n",
    "    print(f\"{i:2d}: {_cnt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e502ef",
   "metadata": {},
   "source": [
    "## Train set에서 Completion task용 dataset 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "36c4eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_compl = []\n",
    "labels_train_compl = []\n",
    "labels_train_compl_class = []\n",
    "for recipe, label in zip(data_train, labels_train):\n",
    "    for i in range(len(recipe)):\n",
    "        data_train_compl.append(recipe[:i]+recipe[i+1:])\n",
    "        labels_train_compl.append(recipe[i])\n",
    "        labels_train_compl_class.append(cuisine_id_dict[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "61ff39f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3146, 3229, 3885, 4379, 4390, 5250, 5456, 6187] 2813 6\n",
      "[2813, 3229, 3885, 4379, 4390, 5250, 5456, 6187] 3146 6\n",
      "[2813, 3146, 3885, 4379, 4390, 5250, 5456, 6187] 3229 6\n",
      "[2813, 3146, 3229, 4379, 4390, 5250, 5456, 6187] 3885 6\n",
      "[2813, 3146, 3229, 3885, 4390, 5250, 5456, 6187] 4379 6\n",
      "[2813, 3146, 3229, 3885, 4379, 5250, 5456, 6187] 4390 6\n",
      "[2813, 3146, 3229, 3885, 4379, 4390, 5456, 6187] 5250 6\n",
      "[2813, 3146, 3229, 3885, 4379, 4390, 5250, 6187] 5456 6\n",
      "[2813, 3146, 3229, 3885, 4379, 4390, 5250, 5456] 6187 6\n",
      "[937, 1476, 2172, 2351, 2813, 3350, 3554, 3857, 3978, 5249, 5648] 392 4\n",
      "[392, 1476, 2172, 2351, 2813, 3350, 3554, 3857, 3978, 5249, 5648] 937 4\n",
      "[392, 937, 2172, 2351, 2813, 3350, 3554, 3857, 3978, 5249, 5648] 1476 4\n",
      "[392, 937, 1476, 2351, 2813, 3350, 3554, 3857, 3978, 5249, 5648] 2172 4\n",
      "[392, 937, 1476, 2172, 2813, 3350, 3554, 3857, 3978, 5249, 5648] 2351 4\n",
      "[392, 937, 1476, 2172, 2351, 3350, 3554, 3857, 3978, 5249, 5648] 2813 4\n",
      "[392, 937, 1476, 2172, 2351, 2813, 3554, 3857, 3978, 5249, 5648] 3350 4\n",
      "[392, 937, 1476, 2172, 2351, 2813, 3350, 3857, 3978, 5249, 5648] 3554 4\n",
      "[392, 937, 1476, 2172, 2351, 2813, 3350, 3554, 3978, 5249, 5648] 3857 4\n",
      "[392, 937, 1476, 2172, 2351, 2813, 3350, 3554, 3857, 5249, 5648] 3978 4\n",
      "[392, 937, 1476, 2172, 2351, 2813, 3350, 3554, 3857, 3978, 5648] 5249 4\n",
      "[392, 937, 1476, 2172, 2351, 2813, 3350, 3554, 3857, 3978, 5249] 5648 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, (x, y, z) in enumerate(zip(data_train_compl, labels_train_compl, labels_train_compl_class)):\n",
    "    print(x, y, z)\n",
    "    if i>=20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a0809c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_data_train_compl = data_to_binary_array(data_train_compl, num_ingredients)\n",
    "int_labels_train_compl = np.array(labels_train_compl)\n",
    "int_labels_train_compl_class = np.array(labels_train_compl_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1bcbb459",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(path_container + 'train_compl', 'w') as h5f:\n",
    "    h5f.create_dataset('bin_data', data=bin_data_train_compl, compression=\"gzip\")\n",
    "    h5f.create_dataset('int_labels', data=int_labels_train_compl, compression=\"gzip\")\n",
    "    h5f.create_dataset('bin_labels', data=int_labels_train_compl_class, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84791792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
