{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abfb27b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# h5py 안 될 때\n",
    "#!brew reinstall hdf5\n",
    "#!export CPATH=\"/opt/homebrew/include/\"\n",
    "#!export HDF5_DIR=/opt/homebrew/\n",
    "#!python3 -m pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba75710c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import math\n",
    "from copy import deepcopy\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e31a79ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path_root = '../'\n",
    "path_container = './Container/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bed3b7",
   "metadata": {},
   "source": [
    "### Dataset 가져오기 (1) dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e2e1250",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'brazilian', 1: 'british', 2: 'cajun_creole', 3: 'chinese', 4: 'filipino', 5: 'french', 6: 'greek', 7: 'indian', 8: 'irish', 9: 'italian', 10: 'jamaican', 11: 'japanese', 12: 'korean', 13: 'mexican', 14: 'moroccan', 15: 'russian', 16: 'southern_us', 17: 'spanish', 18: 'thai', 19: 'vietnamese'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(dict, 20)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path_container + 'id_cuisine_dict.pickle', 'rb') as f:\n",
    "    id_cuisine_dict = pickle.load(f)\n",
    "\n",
    "print(id_cuisine_dict)\n",
    "type(id_cuisine_dict), len(id_cuisine_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c047dc7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'brazilian': 0, 'british': 1, 'cajun_creole': 2, 'chinese': 3, 'filipino': 4, 'french': 5, 'greek': 6, 'indian': 7, 'irish': 8, 'italian': 9, 'jamaican': 10, 'japanese': 11, 'korean': 12, 'mexican': 13, 'moroccan': 14, 'russian': 15, 'southern_us': 16, 'spanish': 17, 'thai': 18, 'vietnamese': 19}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(dict, 20)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path_container + 'cuisine_id_dict.pickle', 'rb') as f:\n",
    "    cuisine_id_dict = pickle.load(f)\n",
    "\n",
    "print(cuisine_id_dict)\n",
    "type(cuisine_id_dict), len(cuisine_id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da975806",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Franks Hot Sauce\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(dict, 6714)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path_container + 'id_ingredient_dict.pickle', 'rb') as f:\n",
    "    id_ingredient_dict = pickle.load(f)\n",
    "\n",
    "print(id_ingredient_dict[6694])\n",
    "type(id_ingredient_dict), len(id_ingredient_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7658b76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "561\n",
      "[698, 1039, 4315]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(dict, 6694)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path_container + 'ingredient_id_dict.pickle', 'rb') as f:\n",
    "    ingredient_id_dict = pickle.load(f)\n",
    "\n",
    "print(ingredient_id_dict['lemon grass'])\n",
    "print(ingredient_id_dict['lemongrass'])\n",
    "print(ingredient_id_dict['bread'])\n",
    "type(ingredient_id_dict), len(ingredient_id_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb04258e",
   "metadata": {},
   "source": [
    "### Datastet 가져오기 (2) h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ac0f315",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n_train = [arr_data_train, bin_data_train, int_labels_train, bin_labels_train]\\n_valid_class = [arr_data_valid_class, bin_data_valid_class, int_labels_valid_class, bin_labels_valid_class]\\n_valid_compl = [arr_data_valid_compl, bin_data_valid_compl, int_labels_valid_compl, bin_labels_valid_compl]\\n_test_class = [arr_data_test_class, bin_data_test_class, None, None]\\n_test_compl = [arr_data_test_compl, bin_data_test_compl, None, None]\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "_train = [arr_data_train, bin_data_train, int_labels_train, bin_labels_train]\n",
    "_valid_class = [arr_data_valid_class, bin_data_valid_class, int_labels_valid_class, bin_labels_valid_class]\n",
    "_valid_compl = [arr_data_valid_compl, bin_data_valid_compl, int_labels_valid_compl, bin_labels_valid_compl]\n",
    "_test_class = [arr_data_test_class, bin_data_test_class, None, None]\n",
    "_test_compl = [arr_data_test_compl, bin_data_test_compl, None, None]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80f9a9ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23547, 6714)\n",
      "(23547,)\n",
      "(23547, 20)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(path_container + 'train', 'r') as f:\n",
    "    bin_data_train = f['bin_data'][:]\n",
    "    int_labels_train = f['int_labels'][:]\n",
    "    bin_labels_train = f['bin_labels'][:]\n",
    "\n",
    "print(bin_data_train.shape)\n",
    "print(int_labels_train.shape)\n",
    "print(bin_labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76265323",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7848, 6714)\n",
      "(7848,)\n",
      "(7848, 20)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(path_container + 'valid_class', 'r') as f:\n",
    "    bin_data_valid_class = f['bin_data'][:]\n",
    "    int_labels_valid_class = f['int_labels'][:]\n",
    "    bin_labels_valid_class = f['bin_labels'][:]\n",
    "\n",
    "print(bin_data_valid_class.shape)\n",
    "print(int_labels_valid_class.shape)\n",
    "print(bin_labels_valid_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec2a1500",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7848, 6714)\n",
      "(7848,)\n",
      "(7848, 6714)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(path_container + 'valid_compl', 'r') as f:\n",
    "    bin_data_valid_compl = f['bin_data'][:]\n",
    "    int_labels_valid_compl = f['int_labels'][:]\n",
    "    bin_labels_valid_compl = f['bin_labels'][:]\n",
    "\n",
    "print(bin_data_valid_compl.shape)\n",
    "print(int_labels_valid_compl.shape)\n",
    "print(bin_labels_valid_compl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2af74861",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3924, 6714)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(path_container + 'test_class', 'r') as f:\n",
    "    bin_data_test_class = f['bin_data'][:]\n",
    "\n",
    "print(bin_data_test_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f48f265",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3924, 6714)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(path_container + 'test_compl', 'r') as f:\n",
    "    bin_data_test_compl = f['bin_data'][:]\n",
    "\n",
    "print(bin_data_test_compl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "78089e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2813, 3146, 3229, ..., 6714, 6714, 6714],\n",
       "       [ 392,  937, 1476, ..., 6714, 6714, 6714]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# binary to int\n",
    "x = np.full((2, 6714), 6714) \n",
    "for i, bin_recipe in enumerate(bin_data_train[:2]):\n",
    "    recipe = np.arange(6714)[bin_recipe==1]\n",
    "    x[i][:len(recipe)] = recipe\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc43311",
   "metadata": {},
   "source": [
    "### Ingredient feature vectors (nn.Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "45b005ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 3.2728,  2.0576,  1.7179,  ..., -0.2083, -0.1903,  0.6921],\n",
      "        [-0.8021,  0.2044, -0.7084,  ...,  0.3418,  1.1189, -0.9387],\n",
      "        [-1.4479, -0.9402,  0.0745,  ...,  1.0755, -0.6538,  1.6401],\n",
      "        ...,\n",
      "        [-0.9674, -1.1701, -0.5552,  ..., -0.1652,  0.0517,  0.1858],\n",
      "        [-0.6495,  0.1527,  0.7819,  ..., -2.0525,  0.0562, -0.0381],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       requires_grad=True)\n",
      "torch.Size([6715, 256])\n"
     ]
    }
   ],
   "source": [
    "num_ingredients = pad_idx +1  # = len(id_ingredient_dict) + 1  # +1 for padding (last)\n",
    "max_length = 65  # maximum num of ingredients per recipe\n",
    "embedding_dim = 256\n",
    "\n",
    "\n",
    "Embed = nn.Embedding(num_embeddings=num_ingredients, embedding_dim=embedding_dim, padding_idx=-1)\n",
    "x = torch.LongTensor(arr_data_train[:2])\n",
    "\n",
    "print(Embed.weight)\n",
    "print(Embed.weight.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0c15ee47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3.2728e+00,  2.0576e+00,  1.7179e+00, -2.7353e-01,  1.4686e-03,\n",
      "         2.3524e-02, -8.1430e-01,  1.1356e+00,  4.7671e-01, -1.0477e+00,\n",
      "         5.3869e-01, -1.0514e+00,  2.7868e+00, -3.4840e-01,  1.0300e+00,\n",
      "        -8.8978e-01,  8.7044e-01,  6.7304e-01, -9.6107e-01, -1.5418e-01,\n",
      "        -2.4102e-01,  1.8187e+00, -8.8296e-01,  1.0660e+00, -1.5905e+00,\n",
      "        -2.2823e-01,  2.2334e-01, -3.6037e-01,  1.2920e-01, -2.1590e-01,\n",
      "        -5.8105e-02,  8.6467e-02, -1.0668e+00,  1.3349e+00,  4.5772e-01,\n",
      "        -2.2714e+00, -1.6354e+00, -1.4927e+00, -1.6907e+00, -7.7145e-01,\n",
      "        -1.9655e+00, -4.6343e-01,  2.0147e+00,  1.2299e-01, -1.5589e+00,\n",
      "        -2.7378e+00,  1.5156e+00, -9.3444e-01, -1.0782e-01, -1.4461e+00,\n",
      "         1.4417e+00,  2.2120e+00, -4.1280e-01, -2.2266e+00,  1.9953e+00,\n",
      "        -9.6570e-01,  1.3736e+00, -4.4300e-01, -6.0772e-02,  6.9036e-01,\n",
      "        -4.0267e-01,  1.0846e+00,  1.8355e+00,  8.6360e-01, -8.8971e-01,\n",
      "         2.0524e+00, -1.6007e+00,  1.5747e+00, -1.7398e+00,  9.0807e-01,\n",
      "         5.9216e-02, -1.1432e+00, -1.1599e+00,  9.2581e-01, -3.0731e-02,\n",
      "         8.6048e-01, -1.0651e+00, -1.6072e+00,  4.5106e-02,  1.6303e+00,\n",
      "        -1.2543e+00, -1.2515e+00, -6.9894e-01, -1.1717e+00,  6.8933e-02,\n",
      "        -6.1248e-01, -4.9013e-01, -9.1619e-01,  1.6110e+00,  1.0834e+00,\n",
      "        -9.4158e-02, -2.4712e-01, -9.9056e-01,  5.3300e-01, -7.0714e-01,\n",
      "         1.6655e+00, -1.6201e+00, -3.1241e-01,  2.9150e-01,  4.9732e-02,\n",
      "         1.5437e-01,  3.0275e-01,  1.0326e+00,  7.5156e-01,  4.5065e-01,\n",
      "        -1.0807e+00,  6.2915e-01, -4.5222e-01,  5.3131e-01,  1.5194e-01,\n",
      "         5.4088e-01, -1.1314e+00,  7.8337e-01, -1.5288e+00,  3.1951e-02,\n",
      "         1.1045e+00,  2.4143e-01,  7.4315e-01,  1.9851e+00,  4.1280e-01,\n",
      "         4.9310e-01, -3.1303e-01,  6.7450e-01, -2.6465e+00,  7.8731e-02,\n",
      "         8.2280e-01, -1.5765e+00,  1.0058e+00,  1.3276e+00, -3.7690e-01,\n",
      "         1.2347e+00,  8.2777e-01,  6.6298e-01, -9.8231e-01, -4.8211e-02,\n",
      "         8.0984e-01,  9.5940e-02, -3.4101e-02,  1.4483e-01, -1.4654e+00,\n",
      "        -9.6164e-01,  5.6020e-01,  1.0961e-02, -3.3800e-01,  1.6837e+00,\n",
      "        -1.7566e+00, -2.3237e-02, -8.2513e-01,  4.7748e-01,  2.7977e-01,\n",
      "        -3.3592e-02,  2.6086e+00, -7.6988e-01,  1.1385e+00,  4.2162e-01,\n",
      "        -1.1323e+00, -2.0235e-01, -3.0510e-01, -2.0714e-01,  5.4949e-01,\n",
      "        -8.3178e-01,  2.5846e+00, -2.0120e+00,  5.8670e-01,  5.6655e-01,\n",
      "         1.9291e+00, -2.0299e+00, -5.1044e-01,  7.4994e-01, -6.0640e-01,\n",
      "         6.2231e-01, -1.2417e-01, -8.9067e-01,  1.1671e+00, -1.2527e+00,\n",
      "         6.2743e-01,  7.4939e-01,  1.2040e+00, -5.8309e-01,  7.7882e-01,\n",
      "         5.5612e-02, -9.5073e-02,  2.1193e+00, -7.8695e-02, -1.4606e+00,\n",
      "         1.0138e+00,  1.1445e+00, -3.6197e-01,  1.7906e+00, -1.5123e+00,\n",
      "         1.7952e+00,  2.4308e+00,  1.0479e-01, -1.8019e+00, -6.6979e-01,\n",
      "         3.1150e-01,  2.4381e-01, -8.8694e-02,  1.7753e+00,  8.6254e-01,\n",
      "         6.8500e-01,  9.1671e-01,  2.4100e-01,  1.8511e+00,  1.1745e+00,\n",
      "        -9.1637e-01, -2.3600e+00,  4.7342e-01,  4.4722e-01, -1.1029e+00,\n",
      "        -3.7303e-01, -1.4033e+00,  5.8994e-01,  7.2198e-03, -4.9197e-01,\n",
      "         1.2479e+00, -4.7025e-01, -1.4612e+00,  8.0172e-01, -7.9142e-01,\n",
      "        -2.2215e-01, -2.2955e-01,  1.9734e-01, -8.0461e-01, -4.5792e-01,\n",
      "        -8.1003e-02, -1.1810e+00,  6.9455e-01, -1.1074e+00,  7.8042e-01,\n",
      "        -5.8710e-01, -9.2614e-01,  7.9566e-01,  3.3988e-01, -7.7582e-01,\n",
      "        -1.7333e+00, -2.3113e-01,  4.5119e-01, -1.6823e+00,  6.7847e-01,\n",
      "        -5.6580e-01,  1.1616e+00,  7.8469e-01,  1.5445e+00,  1.9689e+00,\n",
      "        -1.4753e+00, -2.0269e-01,  9.5114e-01, -6.5345e-01, -1.3938e-01,\n",
      "         6.2411e-01, -1.9412e+00, -8.5131e-01, -2.0832e-01, -1.9030e-01,\n",
      "         6.9207e-01], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(Embed.weight[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8fd45a6c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2813, 3146, 3229, 3885, 4379, 4390, 5250, 5456, 6187, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714],\n",
      "        [ 392,  937, 1476, 2172, 2351, 2813, 3350, 3554, 3857, 3978, 5249, 5648,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714]])\n",
      "torch.Size([2, 65, 256])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "with torch.no_grad():\n",
    "    print(Embed(x).size())\n",
    "    print(Embed(x)[0][11]) # zero padded feature matrix! (0번째 recipe는 9개라 10~65번째 feature vector는 zeros.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20d82e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fe16b36",
   "metadata": {},
   "source": [
    "### Models\n",
    "\n",
    "Set transformer: ( https://github.com/juho-lee/set_transformer )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fe4f440c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Building blocks of Set Transformers ##\n",
    "# added masks.\n",
    "\n",
    "class MAB(nn.Module):\n",
    "    def __init__(self, dim_Q, dim_K, dim_V, num_heads, ln=False, dropout=0.2):\n",
    "        super(MAB, self).__init__()\n",
    "        self.dim_V = dim_V\n",
    "        self.num_heads = num_heads\n",
    "        self.fc_q = nn.Linear(dim_Q, dim_V)\n",
    "        self.fc_k = nn.Linear(dim_K, dim_V)\n",
    "        self.fc_v = nn.Linear(dim_K, dim_V)\n",
    "        if ln:\n",
    "            self.ln0 = nn.LayerNorm(dim_V)\n",
    "            self.ln1 = nn.LayerNorm(dim_V)\n",
    "        self.fc_o = nn.Sequential(\n",
    "            nn.Linear(dim_V, 2*dim_V),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2*dim_V, dim_V))\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, Q, K, mask=None):\n",
    "        # Q (batch, q_len, d_hid)\n",
    "        # K (batch, k_len, d_hid)\n",
    "        # V (batch, v_len, d_hid == dim_V)\n",
    "        Q = self.fc_q(Q)\n",
    "        K, V = self.fc_k(K), self.fc_v(K)\n",
    "        \n",
    "        dim_split = self.dim_V // self.num_heads\n",
    "        \n",
    "        # Q_ (batch * num_heads, q_len, d_hid // num_heads)\n",
    "        # K_ (batch * num_heads, k_len, d_hid // num_heads)\n",
    "        # V_ (batch * num_heads, v_len, d_hid // num_heads)\n",
    "        Q_ = torch.cat(Q.split(dim_split, 2), 0)\n",
    "        K_ = torch.cat(K.split(dim_split, 2), 0)\n",
    "        V_ = torch.cat(V.split(dim_split, 2), 0)\n",
    "        \n",
    "        # energy (batch * num_heads, q_len, k_len)\n",
    "        energy = Q_.bmm(K_.transpose(1,2))/math.sqrt(self.dim_V)\n",
    "        if mask is not None:\n",
    "            energy.masked_fill_(mask, float('-inf'))\n",
    "        A = torch.softmax(energy, 2)\n",
    "        \n",
    "        # O (batch, q_len, d_hid)\n",
    "        O = torch.cat((Q_ + A.bmm(V_)).split(Q.size(0), 0), 2)\n",
    "        O = O if getattr(self, 'ln0', None) is None else self.ln0(O)\n",
    "        O = O + self.dropout(self.fc_o(O))\n",
    "        O = O if getattr(self, 'ln1', None) is None else self.ln1(O)\n",
    "        return O\n",
    "\n",
    "class SAB(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, num_heads, ln=False, dropout=0.2):\n",
    "        super(SAB, self).__init__()\n",
    "        self.mab = MAB(dim_in, dim_in, dim_out, num_heads, ln=ln, dropout=dropout)\n",
    "\n",
    "    def forward(self, X, mask=None):\n",
    "        return self.mab(X, X, mask=mask)\n",
    "\n",
    "class ISAB(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, num_heads, num_inds, ln=False, dropout=0.2):\n",
    "        super(ISAB, self).__init__()\n",
    "        self.I = nn.Parameter(torch.Tensor(1, num_inds, dim_out))\n",
    "        nn.init.xavier_uniform_(self.I)\n",
    "        self.mab0 = MAB(dim_out, dim_in, dim_out, num_heads, ln=ln, dropout=dropout)\n",
    "        self.mab1 = MAB(dim_in, dim_out, dim_out, num_heads, ln=ln, dropout=dropout)\n",
    "\n",
    "    def forward(self, X, mask=None):\n",
    "        H = self.mab0(self.I.repeat(X.size(0), 1, 1), X, mask=mask)\n",
    "        return self.mab1(X, H)\n",
    "\n",
    "class PMA(nn.Module):\n",
    "    def __init__(self, dim, num_heads, num_seeds, ln=False, dropout=0.2):\n",
    "        super(PMA, self).__init__()\n",
    "        self.S = nn.Parameter(torch.Tensor(1, num_seeds, dim))\n",
    "        nn.init.xavier_uniform_(self.S)\n",
    "        self.mab = MAB(dim, dim, dim, num_heads, ln=ln, dropout=dropout)\n",
    "        \n",
    "    def forward(self, X, mask=None):\n",
    "        return self.mab(self.S.repeat(X.size(0), 1, 1), X, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c70a1665",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dim_input,\n",
    "                 num_inds=32, dim_hidden=128, num_heads=4, num_layers=2, ln=False):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc = nn.ModuleList(\n",
    "            [ISAB(dim_input, dim_hidden, num_heads, num_inds, ln=ln)] +\n",
    "            [ISAB(dim_hidden, dim_hidden, num_heads, num_inds, ln=ln) for _ in range(num_layers-1)]\n",
    "        )\n",
    "        \n",
    "    def forward(self, X, mask=None):\n",
    "        out = X.detach()\n",
    "        for module in self.enc:\n",
    "            out = module(out, mask=mask)\n",
    "        return out\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_outputs,\n",
    "                 num_inds=32, dim_hidden=128, num_heads=4, ln=False):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec = nn.Sequential(\n",
    "                PMA(dim_hidden, num_heads, num_outputs, ln=ln),\n",
    "                SAB(dim_hidden, dim_hidden, num_heads, ln=ln),\n",
    "                SAB(dim_hidden, dim_hidden, num_heads, ln=ln))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.dec(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2f4590f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(1 \\\n",
    "     +2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb796399",
   "metadata": {},
   "source": [
    "#### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "660267cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size torch.Size([2, 65])\n",
      "input tensor([[2813, 3146, 3229, 3885, 4379, 4390, 5250, 5456, 6187, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714],\n",
      "        [ 392,  937, 1476, 2172, 2351, 2813, 3350, 3554, 3857, 3978, 5249, 5648,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714]])\n",
      "feature size torch.Size([2, 65, 256])\n",
      "feature tensor([[[-0.5348, -1.4913,  0.2564,  ..., -0.3483, -0.3092, -0.0967],\n",
      "         [ 0.8665,  1.1376, -0.3240,  ..., -2.0181,  1.4959, -1.2283],\n",
      "         [-1.2045, -0.3170, -0.1079,  ..., -0.2161, -0.1603,  2.2915],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.1905,  0.2817, -2.3727,  ...,  0.1040,  2.0772, -0.4429],\n",
      "         [ 0.4223,  1.0731, -0.7493,  ...,  1.4029,  1.6655,  0.3441],\n",
      "         [-0.5611, -0.5346, -1.0705,  ...,  1.3175, -0.4137,  1.0584],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.LongTensor(arr_data_train[:2])\n",
    "\n",
    "with torch.no_grad():\n",
    "    print('input size', x.size())\n",
    "    print('input', x)\n",
    "    feature = Embed(x)  # Size 2, 65, 256\n",
    "    print('feature size', feature.size())\n",
    "    print('feature', feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f0d5b797",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2813, 3146, 3229, 3885, 4379, 4390, 5250, 5456, 6187, 6714, 6714, 6714,\n",
       "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
       "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
       "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
       "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
       "         6714, 6714, 6714, 6714, 6714],\n",
       "        [ 392,  937, 1476, 2172, 2351, 2813, 3350, 3554, 3857, 3978, 5249, 5648,\n",
       "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
       "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
       "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
       "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
       "         6714, 6714, 6714, 6714, 6714]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "37eca200",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 size torch.Size([2, 65])\n",
      "x1 tensor([[3146, 2813, 3229, 3885, 4379, 4390, 5250, 5456, 6187, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714],\n",
      "        [ 392,  937, 1476, 2172, 2351, 2813, 3350, 3554, 3857, 3978, 5249, 5648,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "         6714, 6714, 6714, 6714, 6714]])\n",
      "feature1 tensor([[[ 0.8665,  1.1376, -0.3240,  ..., -2.0181,  1.4959, -1.2283],\n",
      "         [-0.5348, -1.4913,  0.2564,  ..., -0.3483, -0.3092, -0.0967],\n",
      "         [-1.2045, -0.3170, -0.1079,  ..., -0.2161, -0.1603,  2.2915],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.1905,  0.2817, -2.3727,  ...,  0.1040,  2.0772, -0.4429],\n",
      "         [ 0.4223,  1.0731, -0.7493,  ...,  1.4029,  1.6655,  0.3441],\n",
      "         [-0.5611, -0.5346, -1.0705,  ...,  1.3175, -0.4137,  1.0584],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "x1 = deepcopy(x)\n",
    "x1[0][:2] = x[0][[1,0]]\n",
    "print('x1 size', x1.size())\n",
    "print('x1', x1)\n",
    "with torch.no_grad():\n",
    "    feature1 = Embed(x1)\n",
    "    print('feature1', feature1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4c52c160",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_sab = SAB(256, 128, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5e915b71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sab(feature) tensor([[[-2.5072e-02, -4.3051e-01,  1.2263e-01,  ...,  1.0302e+00,\n",
      "          -1.1187e+00, -6.9870e-01],\n",
      "         [ 5.2234e-01, -3.1272e-01,  1.7651e-01,  ..., -1.1486e-01,\n",
      "          -1.5416e-01,  6.6038e-01],\n",
      "         [-1.1277e+00, -3.8550e-01, -1.7317e-01,  ...,  7.0273e-01,\n",
      "           2.1384e-01, -1.5691e-01],\n",
      "         ...,\n",
      "         [-5.6566e-02, -1.0434e-01,  8.8718e-02,  ...,  1.7007e-01,\n",
      "          -1.1468e-01, -1.5865e-01],\n",
      "         [-5.6566e-02, -1.0434e-01,  8.8718e-02,  ...,  1.7007e-01,\n",
      "           4.3089e-03, -1.5865e-01],\n",
      "         [-3.2818e-03, -8.6689e-02,  8.8718e-02,  ...,  1.7913e-01,\n",
      "          -1.1468e-01, -1.5865e-01]],\n",
      "\n",
      "        [[ 2.0383e-01,  8.7391e-01,  9.2565e-02,  ...,  4.2228e-01,\n",
      "          -7.6782e-01, -9.0063e-01],\n",
      "         [ 5.9094e-01, -4.9040e-01,  3.3007e-01,  ...,  1.5430e+00,\n",
      "          -1.3899e+00, -1.3009e-01],\n",
      "         [ 1.5809e+00,  1.6993e+00,  7.7491e-01,  ...,  8.7152e-02,\n",
      "          -2.0340e-01,  6.1534e-01],\n",
      "         ...,\n",
      "         [-5.8967e-02,  2.7306e-01,  5.3273e-02,  ...,  2.2625e-01,\n",
      "          -2.4359e-01, -1.6333e-03],\n",
      "         [ 4.6842e-02,  2.7306e-01,  5.3273e-02,  ...,  2.2625e-01,\n",
      "          -2.4359e-01, -1.6333e-03],\n",
      "         [-5.8967e-02,  3.2060e-01,  5.3273e-02,  ...,  2.2625e-01,\n",
      "          -2.4359e-01, -1.6333e-03]]])\n",
      "torch.Size([2, 65, 128])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    z = _sab(feature, mask=enc_mask)\n",
    "    print('sab(feature)',z)\n",
    "    print(z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "23faf472",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_enc = Encoder(256, dim_hidden=128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9a835b7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 65, 256])\n",
      "tensor([[-0.1059, -0.3514, -0.0556,  ..., -0.1083, -0.3708, -0.0339],\n",
      "        [-0.0847, -0.3444, -0.0712,  ..., -0.1353, -0.3869, -0.0893],\n",
      "        [ 0.0056, -0.3685, -0.0652,  ..., -0.1404, -0.3679, -0.1152],\n",
      "        ...,\n",
      "        [-0.1174, -0.3425, -0.0815,  ..., -0.1387, -0.3789, -0.0180],\n",
      "        [-0.0978, -0.3619, -0.0729,  ..., -0.1695, -0.3428, -0.1099],\n",
      "        [-0.1119, -0.1719, -0.0346,  ..., -0.1596, -0.3800, -0.1061]])\n",
      "torch.Size([2, 65, 128])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    code = _enc(feature,mask=enc_mask)\n",
    "    print(feature.size())\n",
    "    print(code[0][15:])\n",
    "    print(code.size())  # Size 2, 65, dim_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "68c57696",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.3806e-01, -1.6879e-01, -1.5313e-01,  ...,  4.2572e-02,\n",
      "          -6.1262e-01, -1.3449e-01],\n",
      "         [ 8.8945e-01, -5.3579e-02, -4.0432e-01,  ..., -5.3693e-01,\n",
      "          -2.5833e-01,  2.4623e-01],\n",
      "         [-2.6637e-01, -1.1682e-01,  4.5651e-01,  ..., -7.3169e-02,\n",
      "          -3.3885e-01, -3.0409e-04],\n",
      "         ...,\n",
      "         [-1.0347e-01, -3.6286e-01, -5.0822e-02,  ..., -1.4331e-01,\n",
      "          -3.7042e-01, -3.4987e-02],\n",
      "         [-1.0872e-01, -3.9430e-01, -3.1552e-02,  ..., -1.6423e-01,\n",
      "          -3.8089e-01, -4.6489e-02],\n",
      "         [-7.7637e-03, -3.6729e-01,  2.1948e-02,  ..., -1.6029e-01,\n",
      "          -3.8810e-01, -1.1545e-01]],\n",
      "\n",
      "        [[-6.5920e-02, -6.1602e-02, -5.3671e-01,  ..., -9.9114e-02,\n",
      "           5.2724e-01,  3.9178e-01],\n",
      "         [ 3.8000e-01, -1.2891e-01,  9.4537e-01,  ...,  6.6126e-02,\n",
      "           5.6672e-01,  3.8232e-01],\n",
      "         [-3.8756e-03, -9.7366e-01,  4.4759e-01,  ...,  2.5574e-02,\n",
      "           1.2526e-01,  3.3804e-01],\n",
      "         ...,\n",
      "         [-9.8407e-02, -2.3293e-01, -8.6488e-02,  ...,  7.4967e-02,\n",
      "          -1.3289e-01,  8.1825e-02],\n",
      "         [-7.7154e-02, -2.2625e-01, -1.1523e-01,  ...,  7.1530e-02,\n",
      "          -9.4403e-02,  8.3961e-02],\n",
      "         [-7.7143e-02, -2.4182e-01, -8.6624e-02,  ...,  1.1203e-01,\n",
      "          -1.0027e-01,  8.3797e-02]]])\n",
      "torch.Size([2, 65, 128])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    code1 = _enc(feature1, mask=enc_mask)\n",
    "    print(code1)\n",
    "    print(code1.size())  # Size 2, 65, dim_hidden  # permutation equivariant! (observe first 2 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d59ebf3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_dec = Decoder(1, dim_hidden=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7422dc22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1497, -0.0521,  0.0675,  0.0652, -0.0708, -0.0593, -0.2947,\n",
      "          -0.1471,  0.0851,  0.0566,  0.0065, -0.1735,  0.0025, -0.0995,\n",
      "           0.3536,  0.1726,  0.0151, -0.0533,  0.3726, -0.1958,  0.3381,\n",
      "           0.0911, -0.0272,  0.1099,  0.0124, -0.1490, -0.0267,  0.2880,\n",
      "          -0.1414,  0.1710, -0.1190,  0.0281, -0.0124,  0.1056,  0.1193,\n",
      "          -0.1263, -0.0005, -0.0351, -0.1742,  0.0507,  0.0696, -0.0749,\n",
      "          -0.1624, -0.3835, -0.0924,  0.0014,  0.1815,  0.1520,  0.0976,\n",
      "          -0.1666, -0.2210,  0.0397, -0.1481, -0.0580, -0.0651,  0.0135,\n",
      "           0.1413,  0.2000,  0.0184, -0.0768,  0.0059,  0.0186, -0.0755,\n",
      "           0.0342,  0.0811, -0.1843, -0.1589,  0.0689,  0.0355, -0.1432,\n",
      "           0.0241, -0.0497, -0.1559,  0.2053,  0.1894,  0.0601,  0.0463,\n",
      "          -0.1679, -0.0293,  0.0903, -0.1158,  0.0468,  0.1738,  0.0413,\n",
      "          -0.2796,  0.0191, -0.3501,  0.1799,  0.0060, -0.0295,  0.0369,\n",
      "          -0.0476, -0.0276,  0.0278,  0.0089,  0.0938,  0.0487, -0.1152,\n",
      "          -0.1191,  0.1782,  0.0834, -0.0364,  0.2256,  0.1005,  0.0992,\n",
      "           0.1079, -0.1941, -0.1848, -0.0204, -0.1543,  0.1132,  0.0947,\n",
      "          -0.0212, -0.0723, -0.0853,  0.2096,  0.2442,  0.0852,  0.0943,\n",
      "           0.3490, -0.0590,  0.0492, -0.1711,  0.0611, -0.1578,  0.1081,\n",
      "          -0.0034, -0.1823]],\n",
      "\n",
      "        [[ 0.0231, -0.1170,  0.0175,  0.0200, -0.0160, -0.1439, -0.2477,\n",
      "          -0.0396,  0.0211, -0.0163,  0.0074, -0.1271,  0.0107, -0.0819,\n",
      "           0.3504,  0.2873, -0.0166, -0.0320,  0.3150, -0.2281,  0.2714,\n",
      "           0.0200,  0.0839,  0.0361,  0.0814, -0.0246, -0.1179,  0.2553,\n",
      "          -0.1951,  0.0974, -0.1884,  0.0124, -0.0238, -0.0847,  0.1500,\n",
      "          -0.1266, -0.0369,  0.0232, -0.2145, -0.0472,  0.0479, -0.1259,\n",
      "          -0.0050, -0.1765, -0.0551,  0.0055,  0.1635,  0.1443,  0.1073,\n",
      "          -0.0882, -0.1106,  0.0860, -0.1961, -0.0909,  0.0124,  0.0117,\n",
      "           0.1596,  0.2741,  0.1992, -0.0533,  0.0656,  0.0262, -0.1199,\n",
      "           0.0832,  0.1562,  0.0228, -0.1426,  0.0805,  0.0097, -0.1980,\n",
      "           0.0628, -0.0152, -0.1593,  0.2989,  0.1215,  0.0922, -0.0236,\n",
      "          -0.1534,  0.0209,  0.0165, -0.1076,  0.0677,  0.1045, -0.0367,\n",
      "          -0.1406, -0.0365, -0.3263,  0.1476,  0.0658, -0.0384,  0.0759,\n",
      "           0.0291, -0.0500, -0.0204, -0.0193,  0.0505, -0.0340, -0.1067,\n",
      "          -0.0805,  0.1345,  0.1625, -0.0473,  0.2186,  0.0329,  0.0656,\n",
      "           0.1487, -0.2473, -0.0555, -0.0869, -0.2955,  0.0636,  0.1272,\n",
      "          -0.0493, -0.0477, -0.0154,  0.2279,  0.1926,  0.1082,  0.1499,\n",
      "           0.3413, -0.0730, -0.1636, -0.1270,  0.0740, -0.1592,  0.1360,\n",
      "           0.0588, -0.0877]]])\n",
      "torch.Size([2, 1, 128])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = _dec(code)\n",
    "    print(out)\n",
    "    print(out.size())  # Size 2, num_output, dim_hidden. FF 적용 직전 vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "08b0aa2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4379, 6714, 4390, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "        6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 3146, 6714,\n",
      "        6714, 2813, 6714, 6714, 6714, 6714, 6714, 6714, 6187, 6714, 6714, 6714,\n",
      "        6714, 6714, 6714, 6714, 6714, 5250, 5456, 6714, 6714, 6714, 6714, 6714,\n",
      "        6714, 3229, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
      "        3885, 6714, 6714, 6714, 6714])\n",
      "torch.Size([2, 1, 128])\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False]])\n",
      "tensor([[ 0.0878,  0.0178,  0.0617,  0.0674,  0.0746, -0.0434,  0.0177,  0.0578,\n",
      "         -0.0719, -0.0664, -0.0203,  0.0731,  0.0247, -0.0104,  0.0809,  0.0609,\n",
      "         -0.0215, -0.0156, -0.0330, -0.0012,  0.0451,  0.0152,  0.0817, -0.0372,\n",
      "         -0.0149,  0.0874, -0.0284, -0.0089, -0.0206, -0.0721, -0.0458,  0.0037,\n",
      "          0.0063, -0.0382,  0.0053,  0.0522, -0.0487,  0.0210, -0.0537,  0.0040,\n",
      "         -0.0494, -0.0455,  0.0549, -0.0250,  0.0017,  0.1193,  0.0399,  0.0400,\n",
      "          0.0415,  0.0798,  0.0374,  0.0249, -0.0559, -0.0936,  0.0676, -0.0591,\n",
      "          0.0064,  0.0808,  0.1034,  0.0420, -0.0116, -0.0170, -0.0235, -0.0028,\n",
      "         -0.0012,  0.0387,  0.1642,  0.0002, -0.0371,  0.0507,  0.0036,  0.0581,\n",
      "          0.0958,  0.0205,  0.0028, -0.0417, -0.0011, -0.0076, -0.0295, -0.0948,\n",
      "          0.1216, -0.0042, -0.0281, -0.0747,  0.0074, -0.0510, -0.0440, -0.0440,\n",
      "          0.0566, -0.0396, -0.0080,  0.0308, -0.0683, -0.0455, -0.0115, -0.0003,\n",
      "         -0.0544,  0.0588,  0.0690,  0.0625, -0.0274, -0.0417, -0.0755, -0.0174,\n",
      "         -0.0780,  0.0417,  0.0023,  0.1017, -0.0117, -0.0036, -0.0079, -0.0932,\n",
      "          0.0016,  0.0322,  0.0050,  0.0264,  0.0090,  0.0532, -0.0803,  0.0073,\n",
      "          0.0071, -0.0770,  0.0075, -0.0095,  0.0113,  0.0943,  0.0766, -0.0363]])\n"
     ]
    }
   ],
   "source": [
    "# permutation invariance\n",
    "\n",
    "with torch.no_grad():\n",
    "    x2 = deepcopy(x)\n",
    "    \"\"\"3146, 2813, 3229, 3885, 4379, 4390, 5250, 5456, 6187\"\"\"\n",
    "    shuf_ind = torch.randperm(x2.size(1))\n",
    "    x2[0] = x2[0][shuf_ind]  # ramdom permuted!\n",
    "    print(x2[0])\n",
    "    feature2 = Embed(x2)\n",
    "    enc_mask2 = deepcopy(enc_mask)\n",
    "    enc_mask2[0] = enc_mask[0][0][shuf_ind]\n",
    "    code2 = _enc(feature2, mask=enc_mask2)\n",
    "    out2 = _dec(code2)\n",
    "    print(out2.size())\n",
    "    print(out2[0].isclose(out[0]))\n",
    "    print(out2[0] - out[0]) # almost the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0a5be0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4f39da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28555db5",
   "metadata": {},
   "source": [
    "### Unified Model: Classification + Completion (CCNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b6713e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2813, 3146, 3229, 3885, 4379, 4390, 5250, 5456, 6187, 6714, 6714, 6714,\n",
       "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
       "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
       "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
       "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
       "         6714, 6714, 6714, 6714, 6714],\n",
       "        [ 392,  937, 1476, 2172, 2351, 2813, 3350, 3554, 3857, 3978, 5249, 5648,\n",
       "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
       "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
       "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
       "         6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714, 6714,\n",
       "         6714, 6714, 6714, 6714, 6714]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9981739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one_hot(x):\n",
    "    if type(x) is not torch.Tensor:\n",
    "        x = torch.LongTensor(x)\n",
    "    if x.dim() > 2:\n",
    "        x = x.squeeze()\n",
    "        if x.dim() > 2:\n",
    "            return False\n",
    "    elif x.dim() < 2:\n",
    "        x = x.unsqueeze(0)\n",
    "    return F.one_hot(x).sum(1)[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "97da6e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6714])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_one_hot(x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9dc4a86f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class CCNet(nn.Module):\n",
    "    def __init__(self, dim_input=256,\n",
    "                 dim_output=20,\n",
    "                 num_items=6714+1, \n",
    "                 num_inds=32, \n",
    "                 dim_hidden=128, \n",
    "                 num_heads=4, \n",
    "                 num_outputs=1+1,  # classification 1 + completion 1\n",
    "                 num_enc_layers=4, \n",
    "                 num_dec_layers=2,\n",
    "                 ln=True,          # LayerNorm option\n",
    "                 dropout=0.2,      # Dropout option\n",
    "                 classify=True,    # completion만 하고 싶으면 False로\n",
    "                 complete=True):   # classification만 하고 싶으면 False로\n",
    "        super(CCNet, self).__init__()\n",
    "        \n",
    "        self.num_heads = num_heads\n",
    "        self.padding_idx = num_items-1\n",
    "        self.classify, self.complete = classify, complete\n",
    "        self.embedding =  nn.Embedding(num_embeddings=num_items, embedding_dim=dim_input, padding_idx=-1)\n",
    "        self.encoder = nn.ModuleList(\n",
    "            [ISAB(dim_input, dim_hidden, num_heads, num_inds, ln=ln)] +\n",
    "            [ISAB(dim_hidden, dim_hidden, num_heads, num_inds, ln=ln) for _ in range(num_enc_layers-1)])\n",
    "        self.pooling = PMA(dim_hidden, num_heads, num_outputs, ln=ln)\n",
    "        self.decoder1 = nn.Sequential(\n",
    "            *[SAB(dim_hidden, dim_hidden, num_heads, ln=ln, dropout=dropout) for _ in range(num_dec_layers)])\n",
    "        self.ff1 = nn.Sequential(\n",
    "            nn.Linear(dim_hidden, dim_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim_hidden, dim_output))\n",
    "        self.decoder2 = nn.ModuleList(\n",
    "            [MAB(dim_hidden, dim_input, dim_hidden, num_heads, ln=ln, dropout=dropout) for _ in range(2)])\n",
    "        self.ff2 = nn.Linear(dim_hidden, num_items-1)\n",
    "    \n",
    "    def make_one_hot(x):\n",
    "        \"\"\" Convert int_data into bin_data, if needed. \"\"\"\n",
    "        if type(x) is not torch.Tensor:\n",
    "            x = torch.LongTensor(x)\n",
    "        if x.dim() > 2:\n",
    "            x = x.squeeze()\n",
    "            if x.dim() > 2:\n",
    "                return False\n",
    "        elif x.dim() < 2:\n",
    "            x = x.unsqueeze(0)\n",
    "        return F.one_hot(x).sum(1)[:,:-1]\n",
    "    \n",
    "    def forward(self, x): \n",
    "        # x(=recipes): (batch, max_num_ingredient=65) : int_data.\n",
    "        if not (self.classify or self.complete):\n",
    "            return\n",
    "        \n",
    "        x = torch.LongTensor(x)\n",
    "        feature = self.embedding(x)\n",
    "        # feature: (batch, max_num_ingredient=65, dim_input=256)\n",
    "        # cf. embedding.weight: (num_items=6715, dim_input=256)\n",
    "        mask = (x == self.padding_idx).repeat(self.num_heads,1).unsqueeze(1)\n",
    "        # mask: (batch*num_heads, 1, max_num_ingredient=65)\n",
    "        code = feature.clone()\n",
    "        for module in self.encoder:\n",
    "            code = module(code, mask=mask)\n",
    "        # code: (batch, max_num_ingredient=65, dim_hidden=128) : permutation-equivariant.\n",
    "        \n",
    "        pooled = self.pooling(code, mask=mask)\n",
    "        # pooled: (batch, num_outputs=2, dim_hidden=128) : permutation-invariant.\n",
    "        \n",
    "        signals = self.decoder1(pooled)\n",
    "        # no mask; signals: (batch, num_outputs=2, dim_hidden=128) : permutation-invariant.\n",
    "        \n",
    "        # split two signals: for classification & completion.\n",
    "        signal_classification = signals[:][0]                   # (batch, dim_hidden=128)\n",
    "        signal_completion = signals.clone()[:][1].unsqueeze(1)  # (batch, 1, dim_hidden=128)\n",
    "        \n",
    "        # Classification:\n",
    "        if self.classify:\n",
    "            logit_classification = self.ff1(signal_classification)  # (batch, dim_output)\n",
    "            if not self.complete:\n",
    "                return logit_clasification\n",
    "        \n",
    "        # Completion:\n",
    "        if self.complete:\n",
    "            bool_x = (make_one_hot(x) == True)\n",
    "            used_ingred_mask = bool_x.repeat(self.num_heads,1).unsqueeze(1)\n",
    "            # used_ingred_mask: (batch*num_heads, 1, num_items-1=6714)\n",
    "            \n",
    "            embedding_weight = self.embedding.weight[:-1].unsqueeze(0).repeat(feature.size(0),1,1)\n",
    "            # embedding_weight: (batch, num_items=6715, dim_input=256)\n",
    "            \n",
    "            for module in self.decoder2:\n",
    "                signal_completion = module(signal_completion, embedding_weight, mask=used_ingred_mask)\n",
    "            logit_completion = self.ff2(signal_completion.squeeze()) # (batch, num_items-1=6714)\n",
    "            logit_completion[bool_x] = float('-inf')\n",
    "            if not self.classify:\n",
    "                return logit_completion\n",
    "\n",
    "        return logit_classification, logit_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ddc5ef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "_model = CCNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "855bbc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0134,  0.0076,  0.3617, -0.0838,  0.1405, -0.3312, -0.2302, -0.2888,\n",
      "          0.2556, -0.1658,  0.1963, -0.1480, -0.2014,  0.5930, -0.0235,  0.1583,\n",
      "         -0.2339, -0.4005,  0.1152, -0.3462],\n",
      "        [ 0.0284, -0.0381,  0.4265, -0.0877,  0.1785, -0.3441, -0.2454, -0.3424,\n",
      "          0.2262, -0.2049,  0.2100, -0.1222, -0.1992,  0.6614,  0.0021,  0.1020,\n",
      "         -0.2523, -0.2883,  0.0336, -0.3439]]) torch.Size([2, 20])\n",
      "tensor([[-0.3969, -0.0151,  0.0779,  ..., -0.7825,  0.2570, -1.4711],\n",
      "        [-0.3927,  0.1244, -0.0351,  ..., -0.9459,  0.2584, -1.6961]]) torch.Size([2, 6714])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logit1, logit2 = _model(arr_data_train[:2])\n",
    "    print(logit1, logit1.size())\n",
    "    print(logit2, logit2.size())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5559599d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "x = torch.LongTensor(arr_data_train[:2])\n",
    "bin_x = make_one_hot(x)\n",
    "\n",
    "print((F.softmax(logit2, dim=-1) == 0).any())\n",
    "logit2[0][torch.where(bin_x[0]==1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a6eb76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
