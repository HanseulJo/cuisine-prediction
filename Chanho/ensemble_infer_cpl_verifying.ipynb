{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30708daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import h5py\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse import lil_matrix, csr_matrix, hstack\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae7421c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 선언 block\n",
    "rec_file_list = [\"./final_recs/Chanho_recs/valid_recs/CF_rec_cpl_dim_64.pickle\",\n",
    "                       \"./final_recs/Chanho_recs/valid_recs/Graph_rec_cpl_1_2_depth_5.pickle\",\n",
    "                       \"./final_recs/Chanho_recs/valid_recs/Graph_rec_cpl_1_4_depth_3.pickle\",\n",
    "                       \"./final_recs/Chanho_recs/valid_recs/Graph_rec_cpl_1_8_depth_3.pickle\",\n",
    "                       \"./final_recs/Chanho_recs/valid_recs/Graph_rec_cpl_1_8_depth_1.pickle\",\n",
    "                       \"./final_recs/Junwon_recs/inference_valid_cpl_completion_DNN_fc_layer_sizes_1024-1024-512-512_batch_16_seed_0.pkl\",\n",
    "                       \"./final_recs/Hanseul_recs/rec_CCNet_valid_cpl_EncFC_PoolPMA_CplPooled_NumEnc5_NumDec0_Hid512_Emb512_Ind10.pickle\",\n",
    "                       \"./final_recs/Hanseul_recs/rec_CCNet_valid_cpl_EncFC_PoolPMA_CplPooled_NumEnc8_NumDec0_Hid512_Emb512_Ind10.pickle\",\n",
    "                       \"./final_recs/Hanseul_recs/rec_CCNet_valid_cpl_EncFC_PoolPMA_CplPooled_NumEnc8_NumDec0_Hid512_Emb512_Ind10.pickle\",\n",
    "                       \"./final_recs/Hanseul_recs/rec_CCNet_valid_cpl_EncHYBRID_PoolPMA_CplPooled_NumEnc3_NumDec0_Hid512_Emb512_Ind16.pickle\",\n",
    "                       \"./final_recs/Hanseul_recs/rec_CCNet_valid_cpl_EncHYBRID_PoolPMA_CplPooled_NumEnc3_NumDec3_Hid512_Emb512_Ind6.pickle\",\n",
    "                       \"./final_recs/Hanseul_recs/rec_CCNet_valid_cpl_EncHYBRID_PoolPMA_CplPooled_NumEnc3_NumDec3_Hid512_Emb512_Ind7.pickle\",\n",
    "                       \"./final_recs/Hanseul_recs/rec_CCNet_valid_cpl_EncHYBRID_PoolPMA_CplPooled_NumEnc3_NumDec3_Hid512_Emb512_Ind10.pickle\",\n",
    "                       \"./final_recs/Hanseul_recs/rec_CCNet_valid_cpl_EncHYBRID_PoolPMA_CplPooled_NumEnc4_NumDec3_Hid512_Emb512_Ind6.pickle\",\n",
    "                       \"./final_recs/Hanseul_recs/rec_CCNet_valid_cpl_EncHYBRID_PoolPMA_CplPooled_NumEnc6_NumDec0_Hid512_Emb512_Ind29.pickle\",\n",
    "                       \"./final_recs/Hanseul_recs/rec_CCNet_valid_cpl_EncHYBRID_SA_PoolPMA_CplEncoded_NumEnc4_NumDec0_Hid512_Emb512_Ind10.pickle\",\n",
    "                       \"./final_recs/Hanseul_recs/rec_CCNet_valid_cpl_EncHYBRID_SA_PoolPMA_CplEncoded_NumEnc6_NumDec0_Hid512_Emb512_Ind10.pickle\",\n",
    "                       \"./final_recs/Hanseul_recs/rec_CCNet_valid_cpl_EncHYBRID_SA_PoolPMA_CplEncoded_NumEnc8_NumDec0_Hid512_Emb512_Ind10.pickle\",\n",
    "                      ]\n",
    "state_dict_path = \"./ensemble_model/ensemble_model_best_cpl.pt\"\n",
    "save_path = './ensemble_model/valid_cpl.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e381026",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecDataset(Dataset):\n",
    "    def __init__(self, recs_list, query_num, item_num, transform=None, target_transform=None):\n",
    "        # rec_matrix = [query num, model_num, item_num]\n",
    "        self.rec_matrix = []\n",
    "        for i in range(query_num):\n",
    "            self.rec_matrix.append(lil_matrix((len(rec_file_list), item_num)))\n",
    "        for i, recs in enumerate(recs_list):\n",
    "            for query in tqdm(recs.keys()):\n",
    "                rec = recs[query]\n",
    "                rec_items, rec_scores = [rec_ for rec_, score in rec], [score for rec_, score in rec]\n",
    "                rec_scores = normalize(np.array(rec_scores)[:,np.newaxis], axis=0).ravel()\n",
    "                for item, score in zip(rec_items, rec_scores):\n",
    "                    self.rec_matrix[query][i, item] = score\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rec_matrix)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rec_matrix = self.rec_matrix[idx].toarray()\n",
    "        if self.transform:\n",
    "            rec_matrix = self.transform(rec_matrix).to(self.device)\n",
    "        return rec_matrix.to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "309af812",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, model_len, k=10):\n",
    "        super(Network, self).__init__()\n",
    "        self.w1 = torch.nn.Parameter(torch.randn(k, model_len))\n",
    "        self.w2 = torch.nn.Parameter(torch.randn(1, k))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #import ipdb; ipdb.set_trace()\n",
    "        x = x.float()\n",
    "        x = torch.einsum('nm, bmp -> bnp', self.w1, x)\n",
    "        x = torch.einsum('nm, bmp -> bnp', self.w2, x).squeeze(1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a30c11f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 7848/7848 [00:00<00:00, 12223.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 7848/7848 [00:00<00:00, 12091.75it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 7848/7848 [00:00<00:00, 10809.48it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 7848/7848 [00:00<00:00, 12129.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 7848/7848 [00:00<00:00, 11854.92it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 7848/7848 [00:00<00:00, 12166.81it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 7848/7848 [00:00<00:00, 12262.62it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 7848/7848 [00:00<00:00, 11890.86it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 7848/7848 [00:00<00:00, 11195.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 7848/7848 [00:00<00:00, 12148.62it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 7848/7848 [00:00<00:00, 11591.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 7848/7848 [00:00<00:00, 11891.40it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 7848/7848 [00:00<00:00, 11718.14it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 7848/7848 [00:00<00:00, 11854.96it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 7848/7848 [00:00<00:00, 11962.98it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 7848/7848 [00:00<00:00, 11764.23it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 7848/7848 [00:00<00:00, 11766.02it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 7848/7848 [00:00<00:00, 11523.83it/s]\n"
     ]
    }
   ],
   "source": [
    "recs_list = []\n",
    "for rec_file in rec_file_list:\n",
    "    with open(rec_file, 'rb') as f:\n",
    "        recs = pickle.load(f)\n",
    "        recs_list.append(recs)\n",
    "\n",
    "query_num = len(recs_list[0])\n",
    "item_num = 6714\n",
    "\n",
    "test_data = RecDataset(recs_list, query_num, item_num, transform=torch.Tensor, target_transform=torch.tensor)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "719393db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:07<00:00, 16.45it/s]\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Network(len(rec_file_list), k=50).to(device)\n",
    "model_state_dict = torch.load(state_dict_path, map_location=device)\n",
    "model.load_state_dict(model_state_dict)\n",
    "\n",
    "\n",
    "def inference(dataloader, model):\n",
    "    rec_lst = []\n",
    "    with torch.no_grad():\n",
    "        for batch, X in tqdm(enumerate(dataloader),total=len(dataloader)):\n",
    "            pred = model(X)\n",
    "            pred = pred.cpu().numpy()\n",
    "            top_recommends = list(np.argmax(pred, axis=1))\n",
    "            rec_lst.extend(top_recommends)\n",
    "    return rec_lst\n",
    "            \n",
    "\n",
    "infer = inference(test_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "979281c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_dict = {}\n",
    "for i, item in enumerate(infer):\n",
    "    infer_dict[i] = [(item, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22f2763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import get_metric\n",
    "h5f_valid = h5py.File('./Container/valid_cpl', 'r')\n",
    "answer = h5f_valid['labels_id'][:].astype(np.int64)\n",
    "h5f_valid.close()\n",
    "answer_dict = {}\n",
    "for i, ans in enumerate(answer):\n",
    "    answer_dict[i] = ans\n",
    "metric = get_metric(infer_dict, answer_dict, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "354a12d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'macro': 0.024269577339615964,\n",
       " 'micro': 0.1596585117227319,\n",
       " 'accuracy': 0.1596585117227319,\n",
       " 'map': 0.1596585117227319,\n",
       " 'recall': 0.1596585117227319,\n",
       " 'recall_rank': 1.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e270dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
